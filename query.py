# query.py
# è¼‰å…¥ç’°å¢ƒè®Šæ•¸ï¼Œ# .env æª”æ¡ˆä¸­æ‡‰åŒ…å« OPENAI_API_KEY
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA
import time
from dotenv import load_dotenv
load_dotenv() 


# è¼‰å…¥å‘é‡è³‡æ–™åº«
embedding = OpenAIEmbeddings()
# ä½¿ç”¨ Chroma ä½œç‚ºå‘é‡è³‡æ–™åº«
db = Chroma(persist_directory="./mydb", embedding_function=embedding)
# æ§‹å»ºæª¢ç´¢å™¨ æ‹¿æœ€æ¥è¿‘çš„ä¸‰æ®µ
retriever = db.as_retriever(search_kwargs={"k": 3})
# æŸ¥è©¢å‘é‡è³‡æ–™åº«
llm = OpenAI(temperature=0)
# ä½¿ç”¨ LangChain çš„ RetrievalQA ä¾†è™•ç†æŸ¥è©¢
qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
# æŸ¥è©¢ç¤ºä¾‹
query = "è«‹å•æŠ—ä¸‰é«˜çš„åŸå‰‡ï¼Ÿ"
# åŸ·è¡ŒæŸ¥è©¢
start = time.time()
result = qa.run(query)
print(f"â±ï¸ å›ç­”ç”¨æ™‚ï¼š{round(time.time() - start, 2)} ç§’")
relevant_docs = retriever.get_relevant_documents(query)
# è¼¸å‡ºæª¢ç´¢åˆ°çš„æ®µè½å’ŒæŸ¥è©¢çµæœ
# print("\nğŸ“„ æª¢ç´¢åˆ°çš„æ®µè½ï¼š")
# for i, doc in enumerate(relevant_docs, 1):
#     print(f"\n--- Chunk {i} ---\n{doc.page_content}\n")

print("\nğŸ” æŸ¥è©¢çµæœï¼š")
print(result)
